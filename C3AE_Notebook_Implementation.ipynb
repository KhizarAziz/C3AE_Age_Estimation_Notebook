{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "C3AE_Notebook_Implementation.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "3ciQwuqGifkQ",
        "tCzX0_3-LTUc"
      ],
      "authorship_tag": "ABX9TyNQHvoyB3lDcXHPo3fS9zl/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KhizarAziz/C3AE_age_estimation_notebook/blob/master/C3AE_Notebook_Implementation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Unh4OybA10VP"
      },
      "source": [
        "\n",
        "\n",
        "> ## **`Clone Repo`**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8u1jqLBeX9_"
      },
      "source": [
        "!git clone https://github.com/KhizarAziz/C3AE_age_estimation_notebook.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ciQwuqGifkQ"
      },
      "source": [
        "\n",
        "\n",
        "> ## **`Download Datasets`**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRCLZ6NrlE8g"
      },
      "source": [
        "#download imdb\n",
        "# !wget https://data.vision.ee.ethz.ch/cvl/rrothe/imdb-wiki/static/imdb_crop.tar\n",
        "#download WIKI\n",
        "!wget https://data.vision.ee.ethz.ch/cvl/rrothe/imdb-wiki/static/wiki_crop.tar"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V57knmyIvI-Q"
      },
      "source": [
        "#extract IMDB-WIKI datasets\n",
        "# !tar -xvf /content/imdb_crop.tar -C /content/C3AE/dataset\n",
        "!tar -xvf /content/wiki_crop.tar -C /content/C3AE_keras/datasets/\n",
        "# morph data\n",
        "# !tar -xvf Morph.tar -C /content/C3AE/dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tCzX0_3-LTUc"
      },
      "source": [
        "\n",
        "\n",
        "> ## **`Preprocess Datasets`**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UV8SazL4Iitv"
      },
      "source": [
        "cd /content/C3AE_keras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8nTHmnm6Nki5"
      },
      "source": [
        "#Wiki-IDMB\n",
        "!python /content/C3AE_keras/preprocessing_scripts/preprocess_WIKI-IMDB.py\n",
        "#Morph\n",
        "# !python /content/C3AE_keras/preprocessing_scripts/preprocess_Morph.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tCIDazkhgL0x"
      },
      "source": [
        "\n",
        "\n",
        "> ## **`Train`**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSLQUDLhH4lG"
      },
      "source": [
        "cd /content/C3AE_keras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g56nhDyAKhSN"
      },
      "source": [
        "from pathlib import Path\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import dlib\n",
        "from net_training import C3AE_net,training_utils\n",
        "import feather\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import ModelCheckpoint,TensorBoard,ReduceLROnPlateau\n",
        "from keras.losses import kl_divergence,mae\n",
        "from keras.metrics import mae\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Em2nf51-f5rN"
      },
      "source": [
        "# initializing params\n",
        "category = 10\n",
        "dropout = 0.2\n",
        "seed = 2019\n",
        "category = category + 2\n",
        "interval = 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56dzAkRZu5xT"
      },
      "source": [
        "# Loading dataset (from .feather file)\n",
        "dataset_dir = Path('/content/C3AE_keras/datasets/wiki_crop/')\n",
        "dataset_df = pd.DataFrame(columns=[\"age\", \"gender\", \"image\", \"org_box\", \"trible_box\", \"landmarks\", \"roll\", \"yaw\", \"pitch\"])\n",
        "for fnames in dataset_dir.glob('*.feather'):\n",
        "  df_chunk = feather.read_dataframe(dataset_dir.joinpath(fnames))\n",
        "  dataset_df = pd.concat([dataset_df,df_chunk],ignore_index=True)\n",
        "dataset_df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j71HUXvy3hb2"
      },
      "source": [
        "#validation split using sklearn.model_selection.train_test_split\n",
        "trainset, testset = train_test_split(dataset_df, train_size=0.8, test_size=0.2, random_state=seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6CawtVR3swp"
      },
      "source": [
        "# making a generator for image and dataset. inside generator we \n",
        "#load img, crop faces (3 sizes -> big,middle,small) then tranform (if aumentation is true) rotate,birhgt etc ect\n",
        "# convert age into 2 point represenation (like on hot encoding)\n",
        "input_imgs_shape = (64,64) # input image shape to network\n",
        "batch_size = 32 \n",
        "require_data_augmentation = False # if this is true, then random noise will be added to images, e.g rotation, brightness, hue etc\n",
        "train_gen = C3AE_net.preprocessing(trainset,batch_size=batch_size, category=category, interval=interval,input_imgs_shape=input_imgs_shape,augmentation=require_data_augmentation,dropout=dropout)\n",
        "validation_gen = C3AE_net.preprocessing(testset, augmentation=require_data_augmentation, category=category, interval=interval)\n",
        "# print(trainset.groupby([\"age\"])[\"age\"].agg(\"count\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMrUg8iihXo_",
        "outputId": "9a874ff4-419f-4607-b90b-aae58bd3cc0d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#checking generator working fine!\n",
        "index = 10\n",
        "for i in train_gen:\n",
        "  print(i[1][0][index],i[1][1][index])\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "29.0 [0.  0.  0.1 0.9 0.  0.  0.  0.  0.  0.  0.  0. ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XdsEkqRAodzs"
      },
      "source": [
        "# just to check how versatile is our dataset\n",
        "# get distribution of ages i.e how many number of rows for each interval i.e lets say for 0-10 years age we have 5000 entries(rows)\n",
        "age_distribution = [trainset[\"age\"][(trainset.age >= x -10) & (trainset.age <= x)].count() for x in range(10, 101, 10)]\n",
        "age_distribution = [age_distribution[0]] + age_distribution + [age_distribution[-1]]\n",
        "print(age_distribution)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mxrdUhbqq7kj"
      },
      "source": [
        "se_net = True # if true, then network will contain SE_Block (GAP + FC + mul), which improved results.\n",
        "using_white_norm = True # if true, then network will contain white_normlization block, which will normalize image brightness and colors. (for better accuracy)\n",
        "models = C3AE_net.build_net(Categories = category, using_SE=se_net, using_white_norm=using_white_norm)\n",
        "\n",
        "# add pretrain weights if exist\n",
        "pretrain_weights_path = Path(\"/content/C3AE_keras/models_saved/wiki_trained__age_mae_7.7194.h5\")\n",
        "if Path.is_file(pretrain_weights_path):\n",
        "  models.load_weights(pretrain_weights_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6_b6GXXaCyO"
      },
      "source": [
        "lr = 0.1\n",
        "adam = Adam(lr=lr)\n",
        "#cate_weight = K.variable(params.weight_factor)\n",
        "weight_factor = 10\n",
        "models.compile(\n",
        "    optimizer=adam,\n",
        "    loss = {'W1':kl_divergence,'age':mae},\n",
        "    metrics={\"age\": mae},\n",
        "    loss_weights={'W1':weight_factor, 'age': 1}\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tmdWv3XIXt4j"
      },
      "source": [
        "class lr_Callback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_begin(self, batch, logs={}):\n",
        "      # Get the current learning rate from model's optimizer.\n",
        "      lr = float(tf.keras.backend.get_value(self.model.optimizer.learning_rate))\n",
        "      print('current epoch lr is: {} '.format(lr))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8o0_6DCFILB"
      },
      "source": [
        "save_path = '/content/C3AE_keras/models_saved/'\n",
        "callbacks = [\n",
        "  ModelCheckpoint(save_path+'WIKI-weights.{epoch:02d}-{val_age_mean_absolute_error:.2f}.hdf5',\n",
        "                  monitor='val_age_mean_absolute_error',\n",
        "                  verbose = 1,\n",
        "                  save_best_only=True,\n",
        "                  model ='min'),\n",
        "             \n",
        "  ReduceLROnPlateau(monitor='val_age_mean_absolute_error', #considered metric\n",
        "                    factor = 0.5, # learning_rate * factor (multiply lr 0.5 to reduce it by 50%)\n",
        "                    patience = 2,# if loss didnt improve this much epochs, then update lr\n",
        "                    min_delta = 0.01, # if model didnt improve this much\n",
        "                    cooldown = 1, # after lr updated, wait this many epochs before apply new lr\n",
        "                    min_lr = 0.001, # lower limit of lr\n",
        "                    mode = 'min'), # loss should go up (max) or down (min)\n",
        "  lr_Callback() # print lr on each epoch, to analyze lr performance.\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qqE8sbYAC66"
      },
      "source": [
        "epochs=2\n",
        "history = models.fit(train_gen, steps_per_epoch=len(trainset) / batch_size, epochs=epochs, callbacks=callbacks, validation_data=validation_gen, validation_steps=len(testset) / batch_size * 3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NIn7XKFlSDDZ"
      },
      "source": [
        "print(history.history.keys())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5wZQ_yDUr7FC"
      },
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.legend(['loss', 'val_loss'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vs_DXajiscIb"
      },
      "source": [
        "plt.plot(history.history['age_loss'])\n",
        "plt.plot(history.history['val_age_loss'])\n",
        "plt.legend(['age_loss', 'val_age_loss'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SEyCvDzDsenK"
      },
      "source": [
        "plt.plot(history.history['W1_loss'])\n",
        "plt.plot(history.history['val_W1_loss'])\n",
        "plt.legend(['W1_loss', 'val_W1_loss'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NncVdbPgsfuf"
      },
      "source": [
        "plt.plot(history.history['age_mean_absolute_error'])\n",
        "plt.plot(history.history['val_age_mean_absolute_error'])\n",
        "plt.legend(['age_mean_absolute_error', 'val_age_mean_absolute_error'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ee59bZINmiJ6"
      },
      "source": [
        "\n",
        "\n",
        "> ## **`Inference`**\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a03aPpVhoOKh"
      },
      "source": [
        "detector = dlib.get_frontal_face_detector()\n",
        "predictor = dlib.shape_predictor(\"/content/C3AE_keras/detector/shape_predictor_68_face_landmarks.dat\")\n",
        "def gen_face(image):\n",
        "  face_rect_list = detector(image)\n",
        "  xmin, ymin, xmax, ymax = face_rect_list[0].left() , face_rect_list[0].top(), face_rect_list[0].right(), face_rect_list[0].bottom() # face_rect is dlib.rectangle object, so extracting values from it\n",
        "  lmarks_list = dlib.full_object_detections()\n",
        "  for face_rect in face_rect_list:\n",
        "    lmarks_list.append(predictor(image, face_rect)) # getting landmarks as a list of objects\n",
        "  return np.array([xmin, ymin, xmax, ymax]), lmarks_list\n",
        "\n",
        "def gen_boundbox(box, landmark):\n",
        "    # getting 3 boxes for face, as required in paper... i.e feed 3 different sized images to network (R,G,B) \n",
        "    xmin, ymin, xmax, ymax = box # box is [xmin, ymin, xmax, ymax]\n",
        "    w, h = xmax - xmin, ymax - ymin\n",
        "    nose_x, nose_y = (landmark.parts()[30].x, landmark.parts()[30].y) # calculating nose center point, so the triple boxes will be cropped according to nose point\n",
        "    w_h_margin = abs(w - h)\n",
        "    top2nose = nose_y - ymin\n",
        "    # Contains the smallest frame\n",
        "    return np.array([\n",
        "        [(xmin - w_h_margin, ymin - w_h_margin), (xmax + w_h_margin, ymax + w_h_margin)],  # out\n",
        "        [(nose_x - top2nose, nose_y - top2nose), (nose_x + top2nose, nose_y + top2nose)],  # middle\n",
        "        [(nose_x - w//2, nose_y - w//2), (nose_x + w//2, nose_y + w//2)]  # inner box\n",
        "    ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Um60VY96mkLj"
      },
      "source": [
        "img = cv2.imread('/content/test.jpg',)\n",
        "model = models"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UqMvA2s4n2xP"
      },
      "source": [
        "try:\n",
        "    bounds, lmarks = gen_face(img)\n",
        "except Exception as e:\n",
        "  print(e)\n",
        "\n",
        "padding = 200\n",
        "new_bd_img = cv2.copyMakeBorder(img, padding, padding, padding, padding, cv2.BORDER_CONSTANT)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGw3Ubc0qenf"
      },
      "source": [
        "for pidx,landmarks in enumerate(lmarks):\n",
        "    trible_box = gen_boundbox(bounds, landmarks)\n",
        "    tri_imgs = []\n",
        "    for bbox in trible_box:\n",
        "        bbox = bbox \n",
        "        h_min, w_min = bbox[0]\n",
        "        h_max, w_max = bbox[1]\n",
        "        cropped_resized_img = cv2.resize(new_bd_img[w_min:w_max, h_min:h_max], (64, 64))\n",
        "        final_img = np.expand_dims(cropped_resized_img,axis=0)\n",
        "        tri_imgs.append(final_img)\n",
        "    print(np.array(tri_imgs).shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6uFSLGqcsRW4"
      },
      "source": [
        "result = models.predict(tri_imgs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jfBde3PSPpYB",
        "outputId": "2a430cce-d2c1-4e89-b50e-ebae6d630995",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(\"Age is: \",result[0][0][0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Age is:  26.070438\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}